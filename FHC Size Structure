library(readxl)
library(tidyverse)
library(isdbayes)
library(brms)
library(tidybayes)

#load data
load("Environment_Wood_FHC_Github.RData")

###General data summaries of length by year
dfhc %>% group_by(Year) %>% summarize(meanTL=mean(Length), SE=sd(Length)/sqrt(length(Length)), 
                                      l25=quantile(Length, probs=0.25), u25=quantile(Length, probs=0.75), 
                                      n=length(Year))

unique(dfhc$Date)

## Model Length by Year - start by determining necessary Priors
get_prior(bf(Length ~ Year, shape~Year),
          data = dfhc %>% mutate(Year=as.factor(Year)),
          family = Gamma(link="log"))

#Simulate potential priors using a range of values based on Schall and Lucchesi 2021 expected Flathead sizes
#create null object to turn into tibble
tib <- NULL 

#For loop used to run multiple r gamma simulations 
#exponenitate the scale parameter based on brms log link
for (i in seq(0.5, 10, .5)){
  for (j in seq(3, 8, 0.5)){
    vector_name<-paste0("sim",i,j)
    sim <- rgamma(n=1000, shape=i, scale=exp(j)) 
    tib <- as_tibble(cbind(tib, sim))
    names(tib)[ncol(tib)] <- paste0(i,",",j)
    }
}

#plot
tib %>% 
  pivot_longer(cols=1:220, names_to = "sim", values_to="values") %>% 
  arrange(sim) %>% 
  group_by(sim) %>% 
  mutate(ID = cur_group_id()) %>% 
  separate_wider_delim(sim, ",", names=c("shape", "scale"))  %>% 
  mutate(shape=as.numeric(shape), 
         scale=as.numeric(scale)) %>%
  ggplot()+
  stat_ecdf(aes(x=values, group=shape, col=shape))+
  scale_x_continuous(limits=c(0,2000))+
  facet_wrap(~scale, nrow = 2)+
  xlab("Total length (mm)")+
  ylab("Cumulative length-frequency distribution")


#Run Bayesian Model
PrePost_Comp <- brm(bf(Length ~ Year, shape ~ Year),
    data = dfhc %>% mutate(Year=as.factor(Year)),
    family = brmsfamily(family="Gamma", link="log", link_shape="identity"),
    file="Gamma_LFComp_variableShape.rds",
    prior=c(prior(normal(5, 2), class="Intercept"),
            prior(normal(0.5, 0.25), class="b"),
            prior(normal(1, 1), class="b", dpar="shape"),
            prior(normal(5,3), class="Intercept", dpar="shape")),
    cores = 4, chains = 4, iter = 2000)

#Perform model checks
summary(PrePost_Comp)
pp_check(PrePost_Comp, ndraws=40, type="dens_overlay_grouped", group = "Year") + 
  theme_classic()+
  ylab("Frequency")+
  xlab("Total length (mm)")+
  theme(axis.text = element_text(size=12), 
        axis.title = element_text(size=16), 
        strip.text = element_text(size=12), 
        legend.text = element_text(size=12))

#ggsave("FigureS3.ppcheck_FHC.jpeg", height=8, width=8, units="in", dpi=800)

#Sample from the posterior
dat_new<-tibble(Year=unique(dfhc$Year))
set.seed(546)
draws <-add_epred_draws(dat_new, PrePost_Comp)
preds <-add_predicted_draws(dat_new, PrePost_Comp)

#Proportion of positive shape beta values
sum(as_draws_df(PrePost_Comp, variable="b_shape_Year2022")$b_shape_Year2022>0)/4000
sum(as_draws_df(PrePost_Comp, variable="b_shape_Year2023")$b_shape_Year2023>0)/4000
sum(as_draws_df(PrePost_Comp, variable="b_shape_Year2024")$b_shape_Year2024>0)/4000

#summarize results of sample and compare to posterior
dfhc %>% group_by(Year) %>% summarize(meanTL=mean(Length), medTL=median(Length))
preds %>% group_by(Year) %>% summarize(meanTL=mean(.prediction), medTL=median(.prediction))
draws %>% group_by(Year) %>% summarize(meanTL=mean(.epred), sd=sd(.epred))

preds %>% group_by(Year) %>% mean_qi(.width=0.5)
#Perform posterior comparison of mean TL values among years
draws_wide<-draws %>%  
  ungroup() %>% 
  select(.draw, Year, .epred) %>% 
  pivot_wider(names_from = Year, values_from=.epred) %>% 
  mutate(mdiff_2022=`2022`-`2018`,
         mdiff_2023=`2023`-`2018`,
         mdiff_2024=`2024`-`2018`,
         mdiff_22_23=`2023`-`2022`, 
         mdiff_22_24=`2024`-`2022`,
         mdiff_23_24=`2024`-`2023`)
sum(draws_wide$mdiff_2022>0)/4000*100
sum(draws_wide$mdiff_2023>0)/4000*100
sum(draws_wide$mdiff_2024>0)/4000*100
sum(draws_wide$mdiff_22_23>0)/4000*100
sum(draws_wide$mdiff_23_24>0)/4000*100

#plot cummulative frequency distributions
preds %>% mutate(Year=as.factor(Year)) %>% 
  ggplot()+
  stat_ecdf(aes(x=.prediction, group=Year, col=Year), linetype=2, linewidth=1)+
  stat_ecdf(data=dfhc,aes(x=Length, col=as.character(Year), group=Year))+
  scale_x_continuous(breaks=seq(0,1600,by=200), limits=c(0,1640))+
  scale_color_manual(values = c("#26045A", "#225ea8", "#41b6c4", "#8EBD9E")) +
  theme_bw()+
  ylab("Freqency")+
  xlab("Total length (mm)")+
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        panel.border=element_blank(),
        axis.line.x = element_line(colour = "black"),
        axis.line.y = element_line(colour = "black"),
        axis.title = element_text(size=16), 
        axis.text = element_text(size=12),
        legend.text = element_text(size=12),
        legend.position = c(0.8,0.3))

#ggsave("Figure3.CummulativeFreq.jpeg", height=5, width=8, units="in", dpi=800)

#Plot posteior overlaps
preds %>% mutate(Year=as.factor(Year)) %>% 
  ggplot(aes(x=.prediction, fill=Year, color=Year))+
  scale_y_continuous()+
  scale_x_continuous(breaks=seq(0,1600,by=200), limits=c(0,1640))+
  ggridges::geom_density_ridges(aes(y=0),alpha=0.4)+
  scale_fill_manual(values = c("#26045A", "#225ea8", "#41b6c4", "#8EBD9E")) +
  scale_color_manual(values = c("#26045A", "#225ea8", "#41b6c4", "#8EBD9E")) +
  labs(x="Total length (mm)",
       y="Frequency")+
  theme_bw()+
  theme(panel.border = element_blank(), 
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank(),
        panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank(),
        axis.line.x = element_line(colour = "black"),
        axis.line.y = element_line(colour = "black"),
        axis.title = element_text(size=14), 
        axis.text = element_text(size=12),
        legend.text = element_text(size=12),
        legend.title=element_blank(),
        axis.ticks.length.y = unit(0, "cm"),
        legend.position="top")

#ggsave("Figure4.PosteriorLFOverlap.jpeg", height=5, width=8, units="in", dpi=800)


#Test for overlap among density distributions
x <- preds %>% filter(Year==2018)
y <- preds %>% filter(Year==2022)

overlapping::overlap(list(x$.prediction, y$.prediction))
#plot(bayestestR::overlap(x$.prediction, y$.prediction))

##########################################################################################
############################### PSD values ###############################################
##########################################################################################
library(FSA)
##View PSD length cut-offs
(fhc.cuts <- psdVal("Flathead Catfish"))

#Data manipulation
all <- dfhc %>% 
  filter(Length >= fhc.cuts["stock"]) %>% 
  mutate(gcat = lencat(Length, breaks=fhc.cuts, use.names = T, drop.levels = T))

#subset by year and calculate PSD w/ Confidence Interval
dat <- all %>% filter(Year==2018) 
psdCalc(~Length, data=dat, species="Flathead Catfish", what = "traditional")

